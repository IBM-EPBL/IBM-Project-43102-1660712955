{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten, MaxPooling2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#load the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#plot the image\n",
    "plt.imshow(X_train[7], cmap=\"gray\")\n",
    "plt.show()\n",
    "print (y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\".Train the Model.ipynb.upload/paste-0.7987650611622792\"     style=\"object-fit:cover\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print (\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print (\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print (\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print (\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Shape of X\\_train: \\(60000, 28, 28\\)\n",
    "\n",
    "Shape of y\\_train: \\(60000,\\)\n",
    "\n",
    "Shape of X\\_test: \\(10000, 28, 28\\)\n",
    "\n",
    "Shape of y\\_test: \\(10000,\\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "##Reshaping so as to convert images for our model\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "print (\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print (\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print (\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print (\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Shape of X\\_train: \\(60000, 28, 28, 1\\)\n",
    "\n",
    "Shape of y\\_train: \\(60000,\\)\n",
    "\n",
    "Shape of X\\_test: \\(10000, 28, 28, 1\\)\n",
    "\n",
    "Shape of y\\_test: \\(10000,\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#one hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## Declare the layers\n",
    "layer_1 = Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1))\n",
    "layer_2 = MaxPooling2D(pool_size=2)\n",
    "layer_3 = Conv2D(32, kernel_size=3, activation='relu')\n",
    "layer_4 = MaxPooling2D(pool_size=2)\n",
    "layer_5 = Dropout(0.5)\n",
    "layer_6 = Flatten()\n",
    "layer_7 = Dense(128, activation=\"relu\")\n",
    "layer_8 = Dropout(0.5)\n",
    "layer_9 = Dense(10, activation='softmax')\n",
    "\n",
    "\n",
    "## Add the layers to the model\n",
    "model.add(layer_1)\n",
    "model.add(layer_2)\n",
    "model.add(layer_3)\n",
    "model.add(layer_4)\n",
    "model.add(layer_5)\n",
    "model.add(layer_6)\n",
    "model.add(layer_7)\n",
    "model.add(layer_8)\n",
    "model.add(layer_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Epoch 1/3\n",
    "\n",
    "1875/1875 \\[==============================\\] \\- 53s 28ms/step \\- loss: 0.9464 \\- accuracy: 0.7818 \\- val\\_loss: 0.1060 \\- val\\_accuracy: 0.9671\n",
    "\n",
    "Epoch 2/3\n",
    "\n",
    "1875/1875 \\[==============================\\] \\- 52s 28ms/step \\- loss: 0.2829 \\- accuracy: 0.9160 \\- val\\_loss: 0.0859 \\- val\\_accuracy: 0.9734\n",
    "\n",
    "Epoch 3/3\n",
    "\n",
    "1875/1875 \\[==============================\\] \\- 53s 28ms/step \\- loss: 0.2217 \\- accuracy: 0.9359 \\- val\\_loss: 0.0826 \\- val\\_accuracy: 0.9736\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#model prediction\n",
    "example = X_train[7]\n",
    "prediction = model.predict(example.reshape(1, 28, 28, 1))\n",
    "print (\"Prediction (Softmax) from the neural network:\\n\\n {}\".format(prediction))\n",
    "hard_maxed_prediction = np.zeros(prediction.shape)\n",
    "hard_maxed_prediction[0][np.argmax(prediction)] = 1\n",
    "print (\"\\n\\nHard-maxed form of the prediction: \\n\\n {}\".format(hard_maxed_prediction))\n",
    "\n",
    "print (\"\\n\\n--------- Prediction --------- \\n\\n\")\n",
    "plt.imshow(example.reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(\"\\n\\nFinal Output: {}\".format(np.argmax(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1/1 \\[==============================\\] \\- 0s 17ms/step\n",
    "\n",
    "Prediction \\(Softmax\\) from the neural network:\n",
    "\n",
    "\\[\\[6.5797940e\\-12 2.3164995e\\-10 8.6871557e\\-07 9.9999344e\\-01 1.0208746e\\-11\n",
    "\n",
    "7.4993591e\\-07 2.3996124e\\-13 3.1544212e\\-07 3.8453463e\\-06 7.9325741e\\-07\\]\\]\n",
    "\n",
    "Hard\\-maxed form of the prediction: \n",
    "\n",
    "\\[\\[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\\]\\]\n",
    "\n",
    "\\-\\-\\-\\-\\-\\-\\-\\-\\- Prediction \\-\\-\\-\\-\\-\\-\\-\\-\\- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\".Compile the model.ipynb.upload/paste-0.4718077882052718\"     style=\"object-fit:cover\"/>\n",
    "\n",
    "Final Output: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#observing the metrices\n",
    "metrices=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(\"Metrices(test loss and Test Accuracy):\")\n",
    "print(metrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Metrices\\(test loss and Test Accuracy\\):\n",
    "\n",
    "\\[0.08263621479272842, 0.9735999703407288\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "image = cv2.imread('test_image.jpg')\n",
    "image = np.full((100,80,3), 12, dtype = np.uint8)\n",
    "grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV)\n",
    "contours,hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "preprocessed_digits = []\n",
    "\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    \n",
    "    # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "    digit = thresh[y:y+h, x:x+w]\n",
    "    \n",
    "    # Resizing that digit to (18, 18)\n",
    "    resized_digit = cv2.resize(digit, (18,18))\n",
    "    \n",
    "    # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "    padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
    "    \n",
    "    # Adding the preprocessed digit to the list of preprocessed digits\n",
    "    preprocessed_digits.append(padded_digit)\n",
    "\n",
    "print(\"\\n\\n\\n----------------Contoured Image--------------------\")\n",
    "import os, types\n",
    "import pandas as pd\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "print=(\"\\n\\n\\n----------------Contoured Image--------------------\")\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()\n",
    "inp = np.array(preprocessed_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-Contoured Image\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\n",
    "\n",
    "<img src=\".observe the model.ipynb.upload/paste-0.07097615257802414\"     style=\"object-fit:cover\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "model.save(\"models/mnistCNN.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}